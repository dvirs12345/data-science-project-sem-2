{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orgenizing the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25329, 23)\n",
      "(241553, 21)\n"
     ]
    }
   ],
   "source": [
    "names = glob.glob('datasets\\Training\\*')\n",
    "training_data  = pd.DataFrame(data=pd.read_csv(glob.glob(str(names[0])+\"\\*\")[-1]))\n",
    "training_data = training_data.loc[training_data['Time']-training_data['Time'][0]>7]\n",
    "training_data = pd.concat([training_data,pd.read_csv('HandRight.csv')],sort=False)\n",
    "training_data['Type'] = str(re.search(r'[a-zA-Z].*[0-9](.*)',glob.glob(str(names[0])+\"\\*\")[-1]).group(1)[:-4])\n",
    "\n",
    "csv_t = pd.read_csv(glob.glob(str(names[0])+\"\\*\")[-2])\n",
    "csv_t = csv_t.loc[csv_t['Time']-csv_t['Time'][0]>7]\n",
    "csv_t['Type'] =  str(re.search(r'[a-zA-Z].*[0-9](.*)',glob.glob(str(names[0])+\"\\*\")[-2]).group(1)[:-4])\n",
    "training_data = pd.concat([training_data, csv_t],sort=False)\n",
    "\n",
    "csv_q = pd.read_csv(glob.glob(str(names[0])+\"\\*\")[-3])\n",
    "csv_q = csv_q.loc[csv_q['Time']-csv_q['Time'][0]>7]\n",
    "csv_q['Type'] =  str(re.search(r'[a-zA-Z].*[0-9](.*)',glob.glob(str(names[0])+\"\\*\")[-3]).group(1)[:-4])\n",
    "training_data = pd.concat([training_data, csv_q],sort=False)\n",
    "print(training_data.shape)\n",
    "for i in list(glob.glob('datasets\\Training\\*')):\n",
    "    names1 = glob.glob(str(i)+\"\\*\") # List of names of all participants in the experiment.\n",
    "    \n",
    "    csv1 = pd.read_csv(names1[-1])\n",
    "    csv1 = csv1.loc[csv1['Time']-csv1['Time'][0]>7]\n",
    "    csv1['Type'] = str(re.search(r'[a-zA-Z].*[0-9](.*)',names1[-1]).group(1)[:-4])\n",
    "    if 'Alone' in names1[-1]:\n",
    "        training_data = pd.concat([training_data, csv1, pd.read_csv('HandRight.csv')],sort=False)\n",
    "    else:\n",
    "        training_data = pd.concat([training_data, csv1],sort=False)\n",
    "        \n",
    "    csv2 = pd.read_csv(names1[-2])\n",
    "    csv2 = csv2.loc[csv2['Time']-csv2['Time'][0]>7]\n",
    "    csv2['Type'] = str(re.search(r'[a-zA-Z].*[0-9](.*)',names1[-2]).group(1)[:-4])\n",
    "    if 'Alone' in names1[-2]:\n",
    "        training_data = pd.concat([training_data, csv2, pd.read_csv('HandRight.csv')],sort=False)\n",
    "    else: \n",
    "        training_data = pd.concat([training_data, csv2],sort=False)\n",
    "    \n",
    "    csv3 = pd.read_csv(names1[-3])\n",
    "    csv3 = csv3.loc[csv3['Time']-csv3['Time'][0]>7]\n",
    "    csv3['Type'] = str(re.search(r'[a-zA-Z].*[0-9](.*)',names1[-3]).group(1)[:-4])\n",
    "    if 'Alone' in names1[-3]:\n",
    "        training_data = pd.concat([training_data, csv3, pd.read_csv('HandRight.csv')],sort=False)\n",
    "    else:\n",
    "        training_data = pd.concat([training_data, csv3],sort=False)\n",
    "\n",
    "training_data['Type'].replace({'Alone':1,'Spontan':2,'Sync':3},inplace=True)\n",
    "\n",
    "del training_data[\" # hands\"]\n",
    "del training_data[\" Hand Type\"]\n",
    "print(training_data.shape)\n",
    "training_data = training_data.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orgenizing the data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27327, 23)\n",
      "(92751, 21)\n"
     ]
    }
   ],
   "source": [
    "names = glob.glob('datasets\\Validation\\*')\n",
    "testing_data  = pd.DataFrame(data=pd.read_csv(glob.glob(str(names[0])+\"\\*\")[-1]))\n",
    "testing_data = pd.concat([testing_data,pd.read_csv('HandRight.csv')],sort=False)\n",
    "testing_data['Type'] = str(re.search(r'[a-zA-Z].*[0-9](.*)',glob.glob(str(names[0])+\"\\*\")[-1]).group(1)[:-4])\n",
    "\n",
    "csv_t = pd.read_csv(glob.glob(str(names[0])+\"\\*\")[-2])\n",
    "csv_t['Type'] =  str(re.search(r'[a-zA-Z].*[0-9](.*)',glob.glob(str(names[0])+\"\\*\")[-2]).group(1)[:-4])\n",
    "testing_data = pd.concat([testing_data, csv_t],sort=False)\n",
    "\n",
    "csv_q = pd.read_csv(glob.glob(str(names[0])+\"\\*\")[-3])\n",
    "csv_q['Type'] =  str(re.search(r'[a-zA-Z].*[0-9](.*)',glob.glob(str(names[0])+\"\\*\")[-3]).group(1)[:-4])\n",
    "testing_data = pd.concat([testing_data, csv_q],sort=False)\n",
    "print(testing_data.shape)\n",
    "for i in list(glob.glob('datasets\\Validation\\*')):\n",
    "    names1 = glob.glob(str(i)+\"\\*\") # List of names of all participants in the experiment.\n",
    "    \n",
    "    csv1 = pd.read_csv(names1[-1])\n",
    "    csv1 = csv1.loc[csv1['Time']-csv1['Time'][0]>7]\n",
    "    csv1['Type'] = str(re.search(r'[a-zA-Z].*[0-9](.*)',names1[-1]).group(1)[:-4])\n",
    "    if 'Alone' in names1[-1]:\n",
    "        testing_data = pd.concat([testing_data, csv1,pd.read_csv('HandRight.csv')],sort=False)\n",
    "    else:\n",
    "        testing_data = pd.concat([testing_data, csv1],sort=False)\n",
    "        \n",
    "    csv2 = pd.read_csv(names1[-2])\n",
    "    csv2 = csv2.loc[csv2['Time']-csv2['Time'][0]>7]\n",
    "    csv2['Type'] = str(re.search(r'[a-zA-Z].*[0-9](.*)',names1[-2]).group(1)[:-4])\n",
    "    if 'Alone' in names1[-2]:\n",
    "        testing_data = pd.concat([testing_data, csv2,pd.read_csv('HandRight.csv')],sort=False)\n",
    "    else:\n",
    "        testing_data = pd.concat([testing_data, csv2],sort=False)\n",
    "    csv3 = pd.read_csv(names1[-3])\n",
    "    csv3 = csv3.loc[csv3['Time']-csv3['Time'][0]>7]\n",
    "    csv3['Type'] = str(re.search(r'[a-zA-Z].*[0-9](.*)',names1[-3]).group(1)[:-4])\n",
    "    if 'Alone' in names1[-3]:\n",
    "        testing_data = pd.concat([testing_data,csv3,pd.read_csv('HandRight.csv')],sort=False)\n",
    "    else:\n",
    "        testing_data = pd.concat([testing_data, csv3],sort=False)\n",
    "    \n",
    "testing_data['Type'].replace({'Alone':1,'Spontan':2,'Sync':3},inplace=True)\n",
    "del testing_data[\" # hands\"]\n",
    "del testing_data[\" Hand Type\"]\n",
    "print(testing_data.shape)\n",
    "testing_data = testing_data.dropna(how ='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data.loc[:, training_data.columns != 'Type']\n",
    "y_train = training_data[[\"Type\"]]\n",
    "X_test = testing_data.loc[:, testing_data.columns != 'Type']\n",
    "y_test = testing_data[[\"Type\"]]\n",
    "X = pd.concat([X_train,X_test],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99792186e-01 1.03296605e-04 3.20631464e-05 3.12073114e-05\n",
      " 1.31946046e-05]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "fit = pca.fit(X)\n",
    "# summarize components\n",
    "print(fit.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Of AdaBoost For The Given Dataset :  0.39736433511696245\n",
      "\n",
      "F-score wighted :  0.30419203586044735\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier(n_estimators=100, base_estimator= None,learning_rate=1, random_state = 1)\n",
    "adaboost.fit(X_train,y_train)\n",
    "y_pred = adaboost.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "accuracy = float(cm.diagonal().sum())/len(y_test)\n",
    "print(\"\\nAccuracy Of AdaBoost For The Given Dataset : \", accuracy)\n",
    "print(\"\\nF-score wighted : \", f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.44740860504805535\n"
     ]
    }
   ],
   "source": [
    "my_scaler = sklearn.preprocessing.StandardScaler()\n",
    "my_scaler.fit(X_train)\n",
    "X_train = my_scaler.transform(X_train)\n",
    "X_test = my_scaler.transform(X_test)\n",
    "classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "score = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy :', score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
